{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La vraisemblance de $n$ variables aléatoires de Bernoulli peut être exprimée ainsi: $\\mathcal{L}(\\beta) = \\prod\\limits_{i=1}^n \\pi(\\bm{x}_i)^{y_i}(1-\\pi(\\bm{x}_i))^{1-y_i}$. On obtient alors la log-vraisemblance $\\mathcal{l}(\\beta) = \\log(\\mathcal{L}(\\beta))$, et connaissant l'expression de $\\pi(\\bm{x}_i)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{l}(\\beta) = \\sum\\limits_{i=1}^n y_i\\beta^T \\bm{x}_i - \\log(1+e^{\\beta^T \\bm{x}_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_\\beta \\mathcal{l}(\\beta) = \\sum\\limits_{i=1}^n y_i\\bm{x}_i^T - \\frac{x_ie^{\\beta^T \\bm{x}_i}}{1 + x_ie^{\\beta^T \\bm{x}_i}} = \\sum\\limits_{i=1}^n x_i^T(y_i-\\pi(\\bm{x}_i))$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En notation matricielle:\n",
    "\n",
    "$$\\nabla_\\beta\\mathcal{l}(\\beta) = X^T(\\bm{y} - \\bm{\\pi})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_\\beta (\\nabla_\\beta l(\\beta)) = \\nabla_\\beta \\sum\\limits_{i=1}^n [y_i - \\pi(x_i)]x_i = \\sum\\limits_{i=1}^n \\nabla_\\beta [y_i - \\pi(x_i)]x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit,\n",
    "$$\\nabla_\\beta (\\nabla_\\beta l(\\beta)) = \\sum\\limits_{i=1}^n \\nabla_\\beta \\left[\\frac{1}{1 + e^{-\\beta^Tx_i}} \\right] x_i = \\sum\\limits_{i=1}^n \\left[\\frac{1}{1 + e^{-\\beta^Tx_i}} \\right]^2 e^{-\\beta^Tx_i} (-x_i)^T x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'où:\n",
    "\n",
    "$$\\nabla_\\beta (\\nabla_\\beta l(\\beta)) = -\\sum\\limits_{i=1}^n \\left[\\frac{e^{-\\beta^Tx_i}}{1 + e^{-\\beta^Tx_i}} \\right] \\left[\\frac{1}{1 + e^{-\\beta^Tx_i}} \\right] x_i^T x_i = -\\sum\\limits_{i=1}^n \\pi(x_i)[1 - \\pi(x_i)] x_i^T x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis en notation matricielle $\\nabla_\\beta (\\nabla_\\beta l(\\beta)) = -X^TVX$ avec $V=\\text{diag}(\\pi(x_i)[1 - \\pi(x_i)]_{1\\leq i\\leq n})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le développement en série de Taylor de $\\mathcal{l}(\\beta)$ est $\\begin{equation}\\mathcal{l}(\\beta) = \\mathcal{l}(\\beta^{(s)}) + \\nabla_\\beta\\mathcal{l}(\\beta^{(s)})^T(\\beta - \\beta^{(s)}) + \\frac{1}{2}(\\beta - \\beta^{(s)})^T\\nabla\\nabla_\\beta\\mathcal{l}(\\beta^{(s)})(\\beta - \\beta^{(s)}) + r(\\beta - \\beta^{(s)}),\\end{equation}$ où $r(\\beta - \\beta^{(s)})$  est petit comparé à $\\|\\beta - \\beta^{(s)}\\|$. En dérivant $\\mathcal{l}(\\beta)$ selon $\\beta$, pris au maximum, on trouve l'équation:\n",
    "$\\begin{equation}0 =  \\nabla_\\beta\\mathcal{l}(\\beta^{(s)}) + \\nabla\\nabla_\\beta\\mathcal{l}(\\beta^{(s)})(\\beta - \\beta^{(s)}).\\end{equation}$ Et finalement, on trouve la solution $\\beta^{(s+1)}$ telle que:\n",
    "$\\begin{equation}\\beta^{(s+1)} =  \\beta^{(s)} - (\\nabla\\nabla_\\beta\\mathcal{l}(\\beta^{(s)}))^{-1}\\nabla_\\beta\\mathcal{l}(\\beta^{(s)}),\\end{equation}$ donc on trouve la formule itérative à $s$ : $\\beta^{(s+1)} =  \\beta^{(s)} + (X^TV^{(s)}X)^{-1}X^T(\\bm{y} - \\bm{\\pi}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme le polynôme $X\\mapsto X(1-X)$ est majoré par $\\frac{1}{4}$ pour $X=\\frac{1}{2}$, on trouve que $\\pi^{(s)}(x_i)[1 - \\pi^{(s)}(x_i)]\\leq \\frac{1}{4}$, en prenant $H_2 = -(\\frac{1}{4} + \\varepsilon)X^TX$, avec $\\varepsilon > 0$ on trouve que pour tout $v$: $v^T(H_1 -H_2)v=(Xv)^T(\\frac{1}{2}I_n - V^{(s)})Xv=u^T((\\frac{1}{4} + \\varepsilon)I_n - V^{(s)})u>0$ avec $u=Xv$ et donc $H_1 -H_2$ est définie positive.\n",
    "\n",
    "\n",
    "**Question 4.**\n",
    "\n",
    "\n",
    "En prenant la limite lorsque $\\varepsilon\\rightarrow 0$, $\\beta^{(s+1)} =  \\beta^{(s)} + 4(X^TX)^{-1}X^T(\\bm{y} - \\bm{\\pi}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.**\n",
    "\n",
    "- Le terme de pénalité assure plus de stabilité dans l'estimateur $\\hat\\beta$, on s'assure qu'il reste dans une boule d'un rayon fixé $R$, $\\|\\beta\\|_2^2<R^2$.\n",
    "- En grande dimension, pour peu d'observations, le terme rend la matrice définie positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les expressions du gradient et de la hessienne deviennent alors:\n",
    "\n",
    "$$\\nabla_\\beta\\mathcal{l}(\\beta) = X^T(\\bm{y} - \\bm{\\pi}) - \\lambda\\beta$$\n",
    "$$\\nabla_\\beta (\\nabla_\\beta l(\\beta)) = -X^TVX -\\lambda I_n$$\n",
    "\n",
    "Donc finalement: $\\beta_\\lambda^{(s+1)} =  \\beta_\\lambda^{(s)} + 4(X^TX + 4\\lambda I_n)^{-1}(X^T(\\bm{y} - \\bm{\\pi})- \\lambda\\beta_\\lambda^{(s)}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{l}(\\beta) = \\sum\\limits_{i=1}^n y_i\\beta^T \\bm{x}_i - \\log(1+e^{\\beta^T \\bm{x}_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximiser la log-vraisemblence pénalisée équivaut à minimiser la quantité:\n",
    "\n",
    "$$\\min\\limits_{\\beta\\in\\mathbb{R}^p}\\sum\\limits_{i=1}^n \\log(1+e^{\\beta^T \\bm{x}_i}) + \\frac{\\lambda}{2}\\|\\beta\\|_2^2 -y_i\\beta^T \\bm{x}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
